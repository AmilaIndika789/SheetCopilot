**SheetCopilot**: Bringing Software Productivity to the Next Level through Large Language Models
========

<p align="center">
<img src="assets/icon.png" width="50%">
</p>

<p align="center">
<br />
<a href="https://sheetcopilot-demo.github.io/"><strong>Explore the project website »</strong></a>
<br />
</p>

We release the SheetCopilot as well as the evaluation environment in this repository.

SheetCopilot is an assistant agent that manipulate spreadsheets by following user commands. It breaks new ground in human-computer interaction, opening up possibilities for enabling non-expert users to complete their mandane work on complex software (e.g. Google sheets and Excel) via a language interface.

# How SheetCopilot Works

SheetCopilot employs a novel way of directing Large Language Models (LLMs) to manipulate spreadsheets like a human expert. To achieve elegant closed-loop control, SheetCopilot observes the spreadsheet state and polishes generated solutions according to external action documents and error feedback, thereby improving its success rate and efficiency.

<p align="center">
<img src="assets/SheetCopilot-teaser.png" width="100%">
</p>
<br>

# Setup
### 1. Prepare the Conda environment

Python 3.10 is required to support the asyncronous implementation of SheetCopilot.

```
conda create -n habitat python=3.10
```

### 2. In this conda env, run:

```
pip install -r requirements.txt
```


# Dataset
We release a spreadsheet task dataset (v1) containing 28 workbooks and 221 tasks applied to these workbooks. Each task is given one or more hand-made solutions.

Here is the overview of the dataset:

<p align="center">
<img src="assets/two_clouds.png" width="85%">
</p>
<br/>

This dataset can be used to evaluate any spreadsheet manipulation agent including RL, LLM-based or rule-based methods.

In the ```dataset_v1``` folder, ```dataset.xlsx``` lists the 221 tasks, containing the target workbook name, task number, instruction, task categories, and involved atomic actions.

The ```task_sheets``` folder contains the 28 evaluation workbooks these tasks applied to.

The ```task_sheet_answers``` folder contains the reference solutions of the tasks. Each solution consists of a reference workbook showing the expected outcome of the corresponding task instruction and a *.yaml file listing the necessary sheet states to compare. If the necessary states of the result matches any of the references, the result is seen as correct.

The ```dataset_20Samples.xlsx``` file lists the 20 selected tasks used to compare the LLMs in our experiments.


# Evaluation
The results generated by any method should be organized like this:

```
results_dir
  └── ([NO.]_[Sheet Name])
  └── 1_BoomerangSales
  |   └── ([NO.]_[Sheet Name]_[Repeat_NO.].xlsx)
  |   └── 1_BoomerangSales_1.xlsx
  |   ...
  |   └── 1_BoomerangSales_3.xlsx
  ...
  └── 9_BoomerangSales
  ...
  └── 1_Dragging
  ...
  └── 8_Dragging
  ...
```

[Sheet Name] and [NO.] are columns A and B in ```dataset.xlsx```. [Repeat_NO.] is used to differentiate multiple repeats of the same task. If you run each task only once, [Repeat_NO.] is 1.

Run this code within ```eval``` to evaluate your results:
```
python .\evaluation.py -d [result dir] -r [number of repeats]
```

The evaluation results will be recorded in a file named ```eval_result.yaml``` under the result folder.

The evaluation can restart from a checkpoint if it has been aborted.

NOTE that every new sheet must be created to the left of the very first sheet for correct matching with the references since sheet names are not to be checked.

## Evaluation results

The performaces of SheetCopilot with 3 leading LLMs as its back-end on ```dataset_v1/dataset_20Samples.xlsx```.

| Models        | Exec@1 | Pass@1 | A50  | A90  |
|---------------|--------|--------|------|------|
| GPT-3.5-Turbo | 85.0%  | 45.0%  | 2.00 | 4.50 |
| GPT-4         | 65.0%  | 55.0%  | 1.33 | 2.00 |
| Claude        | 80.0%  | 40.0%  | 1.50 | 4.40 |

The performaces of SheetCopilot and a VBA-based method on ```dataset_v1/dataset.xlsx```.

| Methods       | Exec@1 | Pass@1 |
|---------------|--------|--------|
| GPT-3.5-Turbo | 87.3%  | 44.3%  |
| VBA-based     | 77.8%  | 37.1%  |

# SheetCopilot Usage

Firt of all, an OpenAI API key is required.

## For Excel
Coming soon...

## For Google Sheets
Coming soon...

## Which aspects of a spreadsheet can SheetCopilot control
(1) Manipulation: Writing values and formulas, deleting cells, inserting a row/column, autofilling, copy-pasting values, find-and-replacing, setting hyperlinks, removing duplicates, creating sheets, clearing formats.

(2) Management: Sorting, filtering, and freezing panes.

(3) Formatting: Setting format and conditional format (font, bold, italic, underline, text color, and fill color), setting data type (date, text, number, currency, time, general, percentage), and merging.

(4) Charts: Creating charts, creating charts from pivot tabls, setting chart title/axis title/legends/chart type/marker/trendline/data labels.

(5) Pivot table: Creating pivot tables.

(More operations will be added once the developers finish testing them. Besides, you can raise issues to ask for more supported operations or pull request to contribute your implementations.) 

# Citation
SheetCopilot and the dataset can only be used for non-conmercial purposes.

If you use the SheetCopilot framework or data, feel free to cite us.

```bibtex
@misc{li2023sheetcopilot,
  title={SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models},
  author={Hongxin Li and Jingran Su and Yuntao Chen and Qing Li and Zhaoxiang Zhang},
  journal={arXiv preprint arXiv:2305.19308},
  year={2023}
}