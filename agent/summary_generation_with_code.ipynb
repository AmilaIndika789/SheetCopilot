{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "from prompt import Prompt\n",
    "from utils.ChatGPT import ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = \"./config/config.yaml\"\n",
    "OUTPUT_PATH = \"../benchmark_dir\"\n",
    "AGENT_NAME = \"ChatGPT\" # Available: ChatGPT, Llama_3_1, Gemma_2, Mistral\n",
    "MODEL_NAME = \"gpt-4o-mini\" # Available: gpt-4o, gpt-4o-mini, llama-3.1-70b-versatile, gemma2-9b-it, mixtral-8x7b-32768"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_agent_configuration(configuration_file_path, agent_name):\n",
    "    with open(configuration_file_path, mode=\"r\") as file:\n",
    "        config = yaml.load(file, Loader=yaml.Loader)\n",
    "\n",
    "    agent_config = config[\"Agent\"]\n",
    "    # GPT-4o-mini\n",
    "    if agent_name == \"ChatGPT\":\n",
    "        agent_config[\"ChatGPT_1\"][\"api_keys\"] = [os.environ[\"OPENAI_API_KEY\"]]\n",
    "    else:\n",
    "        agent_config[\"Llaama_3_1\"][\"api_keys\"] = [os.environ[\"GROQ_API_KEY\"]]\n",
    "        agent_config[\"Gemma_2\"][\"api_keys\"] = [os.environ[\"GROQ_API_KEY\"]]\n",
    "        agent_config[\"Mistral\"][\"api_keys\"] = [os.environ[\"GROQ_API_KEY\"]]\n",
    "    return agent_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_if_non_existing(path):\n",
    "    pathlib.Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prompt(prompt, test_input_file_path, agent_config, few_shot_count):\n",
    "    prompt_filename = test_input_file_path.split('\\\\')[-1].split('.')[0] + '_prompt.txt'\n",
    "    agent_name = agent_config[\"ChatGPT_1\"][\"model_name\"]\n",
    "    create_path_if_non_existing(f\"{OUTPUT_PATH}/{agent_name}/prompts/{few_shot_count}_shot\")\n",
    "    with open(f\"{OUTPUT_PATH}/{agent_name}/prompts/{few_shot_count}_shot/{prompt_filename}\", \"w\") as file:\n",
    "        file.write(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gpt_response(predicted_instructions, test_input_file_path, agent_config, few_shot_count):\n",
    "    gpt_response_filename = test_input_file_path.split('\\\\')[-1].split('.')[0] + \"_gpt_response.yaml\"\n",
    "    gpt_response = {\"gpt_response\": predicted_instructions}\n",
    "    agent_name = agent_config[\"ChatGPT_1\"][\"model_name\"]\n",
    "    create_path_if_non_existing(f\"{OUTPUT_PATH}/{agent_name}/gpt_responses/{few_shot_count}_shot\")\n",
    "    with open(f\"{OUTPUT_PATH}/{agent_name}/gpt_responses/{few_shot_count}_shot/{gpt_response_filename}\", \"w\") as file:\n",
    "        yaml.dump(gpt_response, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config = set_agent_configuration(configuration_file_path=CONFIG_FILE, agent_name=AGENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Few-shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = Prompt(\n",
    "    agent_configuration=agent_config, agent_name=AGENT_NAME, model_name=\"llama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples = prompt.create_few_shot_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_prompt = prompt.create_actual_prompt(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '- Sort(source=\"Sheet1!A2:G19\", key1=\"Sheet1!C1\", order=\"asc\", '\n",
      "            'orientation=\"column\")\\n'\n",
      "            '\\n'\n",
      "            'Here is the supplementary documentation you can reference:\\n'\n",
      "            \"['Sort(source: str, key1: str, order: str=\\\\'asc\\\\', orientation: \"\n",
      "            \"str=\\\\'column\\\\')\\\\nArgs explanation:\\\\nsource (string): The \"\n",
      "            'range to sort.\\\\nkey1 (string): The key to sort by.\\\\norder '\n",
      "            \"(string): The order to sort by. It can be \\\\'asc\\\\' or \"\n",
      "            \"\\\\'desc\\\\'.\\\\norientation (string): The orientation to sort by. \"\n",
      "            \"It can be \\\\'column\\\\' or \\\\'row\\\\'.\\\\n\\\\nUsage example:\\\\n# \"\n",
      "            'Example 1: Sort the range (A1:E6) in Sheet1 by the first column '\n",
      "            '(i.e. A column) in ascending order.\\\\nSort(\"Sheet1!A2:E6\", '\n",
      "            '\"Sheet1!A1\", \"asc\", \"column\") # Exculde the first row (i.e. '\n",
      "            \"A1:E1) because it is the header.\\\\n']\\n\"\n",
      "            'Here is the corresponding sheet state:\\n'\n",
      "            'Sheet state: Sheet \"Sheet1\" has 7 columns (Headers are A: '\n",
      "            '\"Invoice No.\", B: \"Date\", C: \"Sales Rep\", D: \"Product\", E: '\n",
      "            '\"Price\", F: \"Units\", G: \"Sales\") and 19 rows (1 header row and 18 '\n",
      "            'data rows).\\n'\n",
      "            '\\n',\n",
      " 'role': 'system'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(actual_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_examples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_examples = []\n",
    "for example_index in range(no_of_examples):\n",
    "    # example_src_file_path = excel_file_paths[example_index]\n",
    "    # example_input_file_path = input_file_paths[example_index]\n",
    "\n",
    "    # path_generator = create_path_generator(\n",
    "    #     file_path=f\"{OUTPUT_PATH}/intermediate_responses/\"\n",
    "    # )\n",
    "    # correct_response_file_paths = [str(path) for path in path_generator]\n",
    "\n",
    "    # example_correct_file_path = correct_response_file_paths[example_index]\n",
    "\n",
    "    # example_sheet_state = get_sheet_state(\n",
    "    #     file_path=example_src_file_path, backend=xw_backend\n",
    "    # )\n",
    "\n",
    "    example = (\n",
    "        \"USER\\n\"\n",
    "        \"{input_example}\\n\"\n",
    "        \"Here is the supplementary documentation you can reference:\\n\"\n",
    "        \"{documentation_example}\\n\"\n",
    "        \"Here is the corresponding sheet state:\\n\"\n",
    "        \"{sheet_state_example}\\n\\n\"\n",
    "        \"ASSISTANT\\n\"\n",
    "        \"{correct_example}\\n\"\n",
    "    )\n",
    "\n",
    "    example = example.format(\n",
    "        input_example=get_input_functions(example_input_file_path),\n",
    "        documentation_example=extract_docs_for_input_functions(\n",
    "            input_file_path=example_input_file_path,\n",
    "            agent_config=agent_config,\n",
    "            api_doc=api_doc,\n",
    "        ),\n",
    "        correct_example=get_correct_summarization(\n",
    "            correct_file_path=example_correct_file_path\n",
    "        ),\n",
    "        sheet_state_example=get_sheet_state(\n",
    "            file_path=example_src_file_path, backend=xw_backend\n",
    "        ),\n",
    "    )\n",
    "    few_shot_examples.append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set (except one-shot example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_chat_gpt(prompt):\n",
    "    try:\n",
    "        chatbot = ChatGPT(agent_config[\"ChatGPT_1\"], context=[], interaction_mode=True)\n",
    "        response = await chatbot(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"error occurs when parsing response: {e}\")\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_index in tqdm(range(11, 21)):\n",
    "    test_input_file_path = input_file_paths[test_index]\n",
    "    test_src_file_path = excel_file_paths[test_index]\n",
    "\n",
    "    # Create prompt\n",
    "    prompt = (\n",
    "        \"SYSTEM\\n\"\n",
    "        \"Summarize the each sub-step of instructions into explanations in natural language. \"\n",
    "        \"Be brief and do not provide verbose explanations.\"\n",
    "        \"Avoid redundant steps and provide minimal steps\\n\\n\"\n",
    "        \"{few_shot_examples}\\n\"\n",
    "        \"USER\\n\"\n",
    "        \"{actual_input}\\n\"\n",
    "        \"Here is the supplementary documentation you can reference:\\n\"\n",
    "        \"{actual_documentation}\\n\"\n",
    "        \"Here is the corresponding sheet state:\\n\"\n",
    "        \"{actual_sheet_state}\\n\"\n",
    "    )\n",
    "\n",
    "    # Format the prompt\n",
    "    prompt = prompt.format(\n",
    "        few_shot_examples = \"\\n\".join(few_shot_examples),\n",
    "        actual_input=get_input_functions(test_input_file_path),\n",
    "        actual_documentation=extract_docs_for_input_functions(\n",
    "            input_file_path=test_input_file_path,\n",
    "            agent_config=agent_config,\n",
    "            api_doc=api_doc,\n",
    "        ),\n",
    "        actual_sheet_state=get_sheet_state(\n",
    "            file_path=test_src_file_path, backend=xw_backend\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    save_prompt(prompt, test_input_file_path, agent_config, no_of_examples)\n",
    "\n",
    "    # Get GPT response\n",
    "    response = await call_chat_gpt(prompt)\n",
    "\n",
    "    predicted_instructions = response.split(\"\\n\")\n",
    "    predicted_instructions = [instruction[2:] for instruction in predicted_instructions]\n",
    "    save_gpt_response(predicted_instructions, test_input_file_path, agent_config, no_of_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_ss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
